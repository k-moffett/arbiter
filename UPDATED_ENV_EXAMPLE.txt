# Arbiter Environment Configuration
# Copy this file to .env and update with your values

# ==================================================================
# Logging Configuration
# ==================================================================
# Log prefix to differentiate Arbiter logs from Ollama/other services
LOG_PREFIX=[ARBITER]

# Log format: 'text' for human-readable, 'json' for structured logging
# Use 'json' for parsing with jq or log aggregators
LOG_FORMAT=text

# Log level: DEBUG, INFO, WARN, ERROR, FATAL
LOG_LEVEL=INFO

# Enable colored output in console logs (true/false)
LOG_USE_COLORS=true

# Force console logger even in production (true/false)
LOG_TO_CONSOLE=false

# ==================================================================
# LLM Configuration
# ==================================================================
# LLM model for chat/completions
# Available models (ordered by capability and VRAM requirements):
#   llama3.1:70b-instruct-q4_K_M - Most powerful, requires 48GB+ VRAM
#   qwen2.5:32b                  - Smarter than llama3.1:8b, faster than 70b, requires 20-24GB VRAM
#   qwen2.5:14b                  - Best for 12GB VRAM (RTX 4070), excellent quality/performance balance (DEFAULT)
#   llama3.1:8b                  - Fast and efficient, requires ~8GB VRAM
#   qwen2.5:7b                   - Smaller and faster, requires ~7GB VRAM
LLM_MODEL=qwen2.5:14b

# Embedding model (used for vector search)
EMBEDDING_MODEL=nomic-embed-text

# Component-specific model overrides (optional, defaults to LLM_MODEL)
# Useful for using different model sizes for different RAG pipeline stages
# Example: Use 7b for fast validation, 14b for complex reasoning
# QUERY_DECOMPOSER_MODEL=qwen2.5:14b
# QUERY_ENHANCER_MODEL=qwen2.5:14b
# RAG_VALIDATOR_MODEL=llama3.1:8b      # Use faster model for validation
# QUALITY_GRADER_MODEL=qwen2.5:14b
# TOOL_PLANNER_MODEL=qwen2.5:14b

# ==================================================================
# Ollama Configuration
# ==================================================================
# Ollama server URL
OLLAMA_BASE_URL=http://localhost:11434

# Ollama request timeout in milliseconds
OLLAMA_TIMEOUT=180000

# Enable Ollama debug logging (true/false)
# Note: Ollama logs are separate from Arbiter logs
OLLAMA_DEBUG=false

# Model warming - Pre-load models into memory after startup (true/false)
# This reduces first-request latency but increases startup time
# Recommended: true for production, false for development
OLLAMA_WARM_MODELS=true

# Ollama Model Loading Configuration
OLLAMA_NUM_PARALLEL=2           # Parallel inference requests (2 = embeddings + chat can run simultaneously)
OLLAMA_MAX_LOADED_MODELS=2      # Max models kept in VRAM (2 = embedding model + 1 LLM)
OLLAMA_FLASH_ATTENTION=1        # Enable Flash Attention for faster inference

# Ollama Memory Limits (Docker Deploy Resources)
# Adjust based on your GPU VRAM and models:
#   qwen2.5:14b: 4G reservation, 12G limit (recommended for RTX 4070 12GB)
#   qwen2.5:32b: 8G reservation, 24G limit (requires RTX 4090 24GB+)
OLLAMA_MEMORY_RESERVATION=4G
OLLAMA_MEMORY_LIMIT=12G

# ==================================================================
# Context Window Configuration
# ==================================================================
# Model context limits:
#   qwen2.5:14b: 16K tokens (use 12288 = 75% for safety)
#   qwen2.5:32b: 32K tokens (use 24576 = 75% for safety)
#   llama3.1:8b: 8K tokens (use 6144 = 75% for safety)
CONTEXT_MAX_TOKENS=12288        # Max tokens for retrieved context
CONTEXT_MIN_RESPONSE_TOKENS=512 # Reserved tokens for LLM response
CONTEXT_CHARS_PER_TOKEN=4       # Character-to-token estimation (upgrade to tiktoken later)

# ==================================================================
# RAG Performance Optimization
# ==================================================================
# Query Router Configuration
# Complexity threshold: queries with complexity >5 use complex path (with HyDE + expansion)
# Lower values = better retrieval quality, slightly higher latency
# Higher values = faster but less accurate retrieval
QUERY_ROUTER_COMPLEXITY_THRESHOLD=5    # Complex path for >5 (default: 5, was 7)

# Hybrid Search Configuration
HYBRID_SEARCH_MAX_RESULTS=20    # Reduce from 50 to 20 (fewer results = faster validation)

# RAG Validator Configuration
RAG_VALIDATOR_MAX_PARALLEL=15   # Validate 15 results at once (increased from 5)
RAG_VALIDATOR_MIN_SCORE=0.15    # More permissive threshold (decreased from 0.3)

# ==================================================================
# MCP Server Configuration
# ==================================================================
# MCP Server URL
MCP_SERVER_URL=http://localhost:3100

# Transport type: stdio or streamable-http
TRANSPORT=streamable-http

# HTTP port for MCP server
MCP_HTTP_PORT=3100

# Maximum concurrent requests
MAX_CONCURRENT_REQUESTS=50

# Request timeout in milliseconds
REQUEST_TIMEOUT=30000

# ==================================================================
# Qdrant Configuration
# ==================================================================
# Qdrant vector database URL
QDRANT_URL=http://localhost:6333

# Optional Qdrant API key (leave empty for no auth)
QDRANT_API_KEY=

# ==================================================================
# Node.js Configuration
# ==================================================================
# Environment: development, production, local
NODE_ENV=development

# Node memory options
NODE_OPTIONS=--max-old-space-size=2048

# ==================================================================
# Agent Orchestrator Configuration
# ==================================================================
AGENT_ORCHESTRATOR_URL=http://localhost:3200

# ==============================================================================
# CLI Customization
# ==============================================================================
# Customize the appearance and behavior of the interactive CLI client
# Usage: Set these variables before running: npm run cli

# CLI Welcome Banner
# Title displayed in ASCII art at startup (default: "Arbiter CLI")
CLI_WELCOME_TITLE=Arbiter CLI

# Subtitle message shown below the banner (default: "Context-Aware AI Agent")
CLI_WELCOME_MESSAGE=Context-Aware AI Agent

# Visual Settings
# Enable gradient colors for the welcome banner (default: "true")
# Set to "false" for simpler terminals or accessibility
CLI_USE_GRADIENT=true

# Banner Font
# ASCII art font for the welcome title (default: "Small Slant")
# Options: "Small Slant", "Small", "Mini", "Slant", "none"
#   - Small Slant: Stylish slanted text, compact (~57 chars)
#   - Small: Clean modern text, very compact
#   - Mini: Extremely minimal, single-line style
#   - Slant: Standard slanted text, medium size
#   - none: Disable ASCII art (text only)
CLI_BANNER_FONT=Small Slant

# Gradient theme for the welcome banner (default: "pastel")
# Options: "pastel", "gold", "gold-black", "cyan-purple", "fire", "ocean"
#   - pastel: Soft aqua to pink gradient (default)
#   - gold: Bright gold to orange gradient
#   - gold-black: Gold to black gradient (on-brand theme)
#   - cyan-purple: Cyan to purple gradient
#   - fire: Red to orange gradient
#   - ocean: Deep blue to light cyan gradient
CLI_BANNER_GRADIENT_THEME=pastel

# Custom Gradient Colors (optional)
# Set custom hex colors to override theme selection
# Both START and END must be set to activate custom colors
# Example: CLI_BANNER_GRADIENT_START=#9333EA
#          CLI_BANNER_GRADIENT_END=#3B82F6
# CLI_BANNER_GRADIENT_START=
# CLI_BANNER_GRADIENT_END=

# Animation Style
# Style for the "Thinking..." animation (default: "spinner")
# Options: "spinner", "hourglass", "dots", "bounce", "none"
#   - spinner: Rotating spinner animation (⠋⠙⠹⠸⠼⠴⠦⠧⠇⠏)
#   - hourglass: Alternating hourglass (⏳⌛)
#   - dots: Progressive dots (Thinking, Thinking., Thinking..)
#   - bounce: Bouncing circle (◐◓◑◒)
#   - none: Static text (no animation)
CLI_ANIMATION_STYLE=spinner

# Session Statistics
# Show message count and average response time after each message (default: "false")
# Set to "true" to show statistics, or use /stats command to toggle during session
CLI_SHOW_STATS=false

# Terminal Compatibility Settings
# Force color support even when not detected (useful for PowerShell/WSL)
# Options: "true", "false" (default: auto-detect)
# CLI_FORCE_COLOR=true

# Override terminal width detection (useful for non-TTY or Docker environments)
# Specify number of columns (default: auto-detect, fallback to 100)
# CLI_TERMINAL_WIDTH=100

# Disable ASCII art and use plain text only (maximum compatibility)
# Options: "true", "false" (default: "false")
# Use this if ASCII art doesn't render properly in your terminal
# CLI_ASCII_ONLY=true

# ============================================================================
# CLI Features (Powered by oclif + Clack + Marked)
# ============================================================================
# The CLI now includes:
#   - Interactive commands with oclif framework
#   - Beautiful animations and prompts with Clack
#   - Markdown rendering in agent responses (code blocks, tables, etc.)
#
# Available Commands:
#   arbiter-cli                    # Start interactive chat (default)
#   arbiter-cli history            # View conversation history
#   arbiter-cli history --export   # Export history to markdown
#   arbiter-cli history --search   # Search conversations
#   arbiter-cli config             # View/update configuration
#   arbiter-cli --help             # Show all commands and options
#
# Command Flags:
#   --debug, -d                    # Enable debug mode
#   --stats                        # Show session statistics
#   --theme <theme>                # Set color theme (pastel/gold/gold-black)
#   --session <id>                 # Use custom session ID
#
# Examples:
# Custom branding:
#   CLI_WELCOME_TITLE=My Custom Bot
#   CLI_WELCOME_MESSAGE=Powered by Ollama & Qdrant
#
# Gold and black theme (on-brand):
#   CLI_BANNER_GRADIENT_THEME=gold-black
#
# Custom purple-blue gradient:
#   CLI_BANNER_GRADIENT_START=#9333EA
#   CLI_BANNER_GRADIENT_END=#3B82F6
#
# Compact banner for narrow terminals:
#   CLI_BANNER_FONT=Mini
#
# Hourglass animation instead of spinner:
#   CLI_ANIMATION_STYLE=hourglass
#
# PowerShell/WSL compatibility mode:
#   CLI_FORCE_COLOR=true
#   CLI_TERMINAL_WIDTH=100
#
# Maximum compatibility (plain text only):
#   CLI_ASCII_ONLY=true
#   CLI_USE_GRADIENT=false
#   CLI_BANNER_FONT=none
#
# Minimal mode (no gradients, no animations, no stats):
#   CLI_USE_GRADIENT=false
#   CLI_SHOW_STATS=false
#   CLI_ANIMATION_STYLE=none
