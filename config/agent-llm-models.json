{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Agent LLM Model Configuration",
  "description": "Configuration for LLM model selection per agent type",
  "agentTypes": {
    "query": {
      "provider": "anthropic",
      "model": "claude-sonnet-4",
      "temperature": 0.7,
      "maxTokens": 4096,
      "fallback": {
        "provider": "openai",
        "model": "gpt-4o"
      }
    },
    "research": {
      "provider": "openai",
      "model": "gpt-4o",
      "temperature": 0.5,
      "maxTokens": 8192,
      "fallback": {
        "provider": "ollama",
        "model": "llama3:70b"
      }
    },
    "validation": {
      "provider": "ollama",
      "model": "llama3:70b",
      "temperature": 0.3,
      "maxTokens": 2048,
      "fallback": {
        "provider": "anthropic",
        "model": "claude-haiku-4"
      }
    },
    "synthesis": {
      "provider": "anthropic",
      "model": "claude-sonnet-4",
      "temperature": 0.8,
      "maxTokens": 8192,
      "fallback": {
        "provider": "openai",
        "model": "gpt-4o"
      }
    },
    "specialist": {
      "provider": "anthropic",
      "model": "claude-opus-4",
      "temperature": 0.7,
      "maxTokens": 16384,
      "fallback": {
        "provider": "openai",
        "model": "gpt-4"
      }
    }
  },
  "costOptimization": {
    "enabled": true,
    "useLocalFirst": true,
    "rules": [
      {
        "condition": "queryComplexity < 0.3",
        "provider": "ollama",
        "model": "llama3:70b",
        "reason": "Simple queries can use free local model"
      },
      {
        "condition": "queryComplexity >= 0.7",
        "provider": "anthropic",
        "model": "claude-opus-4",
        "reason": "Complex queries need most capable model"
      },
      {
        "condition": "queryLength > 50000",
        "provider": "anthropic",
        "model": "claude-sonnet-4",
        "reason": "Long context window required"
      }
    ]
  }
}
